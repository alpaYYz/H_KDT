{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNL3sgNR8jRyA8fl7rRFKgS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"Ea16OanJjdaJ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time"],"metadata":{"id":"ud5V0t88jeyn","executionInfo":{"status":"ok","timestamp":1687419176530,"user_tz":-540,"elapsed":5754,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# device setting\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # cuda는 gpu\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OpeOlepOjewB","executionInfo":{"status":"ok","timestamp":1687419176531,"user_tz":-540,"elapsed":15,"user":{"displayName":"유영준","userId":"02892448869014284071"}},"outputId":"f8c80e4d-3df4-4966-8d72-497ef1579443"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Hyper-parameter\n","num_epochs = 5 # 에폭을 다섯번 돌리겠다\n","batch_size = 4 # 에폭의 단위\n","learning_rate = 0.001"],"metadata":{"id":"mLvpvFEJp2ha","executionInfo":{"status":"ok","timestamp":1687419176531,"user_tz":-540,"elapsed":8,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# data preprocesssing\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std =(0.5, 0.5, 0.5))]) # transforms = tensor로 바꾸어줌 mean과 std가 세가지 값이 들어간 이유는 채널수가 3이여서 여기선 (rgb)\n"],"metadata":{"id":"kbk6SR8sjetb","executionInfo":{"status":"ok","timestamp":1687419176531,"user_tz":-540,"elapsed":5,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# # Cifar 10 : 60000 32 X 32 color images for 10 classes # 이미지일때 (3 , x, x) -> 여기서는 (3,32,32) torchvison => 이미지 처리\n","# train_dataset = torchvision.datasets.CIFAR10(root ='./',\n","#                                              train = True,\n","#                                              download = True,\n","#                                              transform = transform)\n","\n","# test_dataset = torchvision.datasets.CIFAR10(root ='./',\n","#                                              test = False,\n","#                                              download = True,\n","#                                              transform = transform)\n","train_dataset = torchvision.datasets.CIFAR10(root='./data',\n","                                             train=True,\n","                                             download=True,\n","                                             transform=transform)\n","\n","test_dataset = torchvision.datasets.CIFAR10(root='./data',\n","                                             train=False,\n","                                             download=True,\n","                                             transform=transform)\n","\n"],"metadata":{"id":"oWBN5wb5jerE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687419183619,"user_tz":-540,"elapsed":7092,"user":{"displayName":"유영준","userId":"02892448869014284071"}},"outputId":"b2409473-37e9-4811-d8fd-e17db9e5a9aa"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 80143855.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True) # dataloader 배치단위로 데이터를 학습 시키거나 데이터를 공급해줌 훈련용데이터는 규칙적인 패턴이 있을수도 있기에 shuffle = True\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n","\n","# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","# test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","# #batch단위로 데이터를 제공"],"metadata":{"id":"mi-MikQyjeoP","executionInfo":{"status":"ok","timestamp":1687419183620,"user_tz":-540,"elapsed":5,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 모델정의\n","class CNN(nn.Module):\n","  def __init__(self): # 데이터의 실행 재료들\n","    super(CNN, self).__init__()\n","    #self를 붙이면 전역변수로 사용 가능\n","    self.conv1 = nn.Conv2d(in_channels= 3, out_channels= 6, kernel_size= 5) # out channel 은 필터의 수 하이퍼파라미터 사용자가 지정하는 수 파라미터 학습되어지는 수 # kernel_size = 5x5\n","    self.pool = nn.MaxPool2d(2, 2) # (krnel size, 스트라이드값)\n","    self.conv2 = nn.Conv2d(6, 16, 5) #x conv1채널의 수(out_channel = 6)가 6이기 떄문에 in_channel = 6이다\n","    self.fc1 = nn.Linear(16*5*5, 100) # 16차원 5x5의 flatten, 100\n","    self.fc2 = nn.Linear(100,50)\n","    self.fc3 = nn.Linear(50,10) # 마지막은 클래스의 숫자\n","\n","  # 실행시킬 구조 (순전파)\n","  def forward(self, x):\n","    x = self.pool(F.relu(self.conv1(x))) # conv1 -> ReLu실행 -> maxpooling 실행-> conv2 -> 반복 -> flatten -> f1 -> f2 -> f3 - > 예측\n","    x = self.pool(F.relu(self.conv2(x))) # ReLu는 shape이 바뀌지 않는다.\n","    #1차원 백터로 flatten\n","    x.view(-1,16*5*5) # (배치사이즈 = -1 ,fc1) -> 1차원 백터로 전환 -1은 배치사이즈 -> (배치사이즈, flatten의 값)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","\n","# class CNN(nn.Module):\n","#   def __init__(self):\n","#     super(CNN, self).__init__()\n","#     self.conv1 = nn.Conv2d(in_channels= 3, out_channels= 6, kernel_size= 5) #3:RGB, 6:필터 수(지정), 5:5x5의 필터 사용\n","#     self.pool = nn.MaxPool2d(2, 2) #(사이즈(2x2), 스트라이드 (2칸씩))\n","#     self.conv2 = nn.Conv2d(6, 16, 5) #6:위애서 필터 수가 6이므로 인채널도6, 16:필터 수\n","#     self.fc1 = nn.Linear(16*5*5, 100)\n","#     self.fc2 = nn.Linear(100, 50)\n","#     self.fc3 = nn.Linear(50, 10) #Cifar10의 클래스가 10이므로 10\n","\n","#   def forward(self, x):\n","#     x = self.pool(F.relu(self.conv1(x)))\n","#     x = self.pool(F.relu(self.conv2(x)))\n","#     x = x.view(-1, 16*5*5) #Flatten #-1:batch\n","#     x = F.relu(self.fc1(x))\n","#     x = F.relu(self.fc2(x))\n","#     x = self.fc3(x)\n","#     return x\n"],"metadata":{"id":"43lzvFuCnrmt","executionInfo":{"status":"ok","timestamp":1687419183620,"user_tz":-540,"elapsed":4,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 높이 공식과 너비의 공식) (W(열의 수 즉 높이)-F(필터의 사이즈) + 2*P(패딩의 개수))/S(스트레이트값)) + 1 for Conv\n","# ((W-(필터의 size))/S)+1 for pooling -> 예 Maxpool2d(size,스트라이드값)"],"metadata":{"id":"jPtw3O_nc_AF","executionInfo":{"status":"ok","timestamp":1687419183620,"user_tz":-540,"elapsed":4,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["test_dataset[0][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETjkn92k-Fu2","executionInfo":{"status":"ok","timestamp":1687419183620,"user_tz":-540,"elapsed":4,"user":{"displayName":"유영준","userId":"02892448869014284071"}},"outputId":"49a65273-74fb-45a6-a420-a8aaf5d3d53a"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 32, 32])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["model = CNN().to(device) # device에 올린다\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZrhVPl-3Kp4","executionInfo":{"status":"ok","timestamp":1687419188849,"user_tz":-540,"elapsed":5232,"user":{"displayName":"유영준","userId":"02892448869014284071"}},"outputId":"4d7694d9-80b4-467a-aec6-87251dbd231a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN(\n","  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=100, bias=True)\n","  (fc2): Linear(in_features=100, out_features=50, bias=True)\n","  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# 손실함수\n","critertion = nn.CrossEntropyLoss() # CNN은 분류이기 때문에 CrossEntropyLoss()사용 회귀면 MSE, MAE\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # adam = > w(가중치)의 최저값을 구해줌 (경사하강법)"],"metadata":{"id":"CtWVnhIcis5o","executionInfo":{"status":"ok","timestamp":1687419188849,"user_tz":-540,"elapsed":10,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#  train\n","n_total_steps = len(train_loader)\n","for epoch in range(num_epochs): # 에폭의 수의 반복\n","  for i, (images, labels) in enumerate(train_loader): # 반복을 할때마다 train_loader를 반복함 - 반복은 배치사이즈로 데이터를 반복함 (image, labels) 은 (x축, y축)\n","    images = images.to(device) # divice로 데이터로 보냄\n","    labels = labels.to(device)\n","\n","    #forward(순전파) 단계\n","    outputs = model(images)\n","    loss = criterion(outputs, labels) # 예측값과 실제값을 예측결과를 확인함\n","\n","    #역전파파 단계\n","    optimizer.zero_grad() # 기울기 초기화\n","    loss.backward() # 오차를 전 단계로 이동시킴 -> 역전파\n","    optimizer.step() # 업데이트시킴\n","\n","    if (i + 1) % 3000 == 0:\n","      print(f'Epoch: {epoch + 1}/ {num_epochs}, Loss: {loss.item(): 3f}')\n","print(\"Finished Training\")\n","\n","#train\n","# n_total_steps = len(train_loader)\n","# for epoch in range(num_epochs): #에폭을 다음 만큼 반복\n","#   for i, (images, labels) in enumerate(train_loader): #배치사이즈로 공급\n","#     images = images.to(device)\n","#     labels = labels.to(device)\n","\n","#     outputs = model(images)\n","#     loss = criterion(outputs, labels)\n","\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     optimizer.step()\n","#     if(i+1) % 3000 == 0:\n","#       print(f'Epoch: {epoch+1}/{num_epochs}, Step: {i+1}/{n_total_steps}, Loss: {loss.item(): 3f}')\n","\n","# print(\"Finished Training!\")"],"metadata":{"id":"DSW039XbjHY6","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"error","timestamp":1687420000504,"user_tz":-540,"elapsed":263,"user":{"displayName":"유영준","userId":"02892448869014284071"}},"outputId":"770169d7-f1cd-4826-c880-8151aa245591"},"execution_count":16,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4addcf1b1232>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#forward(순전파) 단계\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 예측값과 실제값을 예측결과를 확인함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-f72632c46ab5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#1차원 백터로 flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (배치사이즈 = -1 ,fc1) -> 1차원 백터로 전환 -1은 배치사이즈 -> (배치사이즈, flatten의 값)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (320x5 and 400x100)"]}]},{"cell_type":"code","source":["# 평가단계\n","with torch.no_grad(): # 평가할때는 업데이트가 필요 없기에 기울기를 계산하지 않는다 -> grad는 기울기 no_grad\n","  n_correct = 0\n","  n_samples = 0\n","\n","  model.eval() # 학습을 평가할때 사용\n","  # 실행 안될때 각 줄에 print 써보기\n","  for images, labels in test_loader:\n","    images = images.to(device)\n","    images = images.to(device)\n","\n","    outputs = model(images)\n","\n","    _, pred = torch.max(outputs, 1) # max(outputs , 0과 1) -> row와 culumn 즉 dimension -> 토치 맥스는 인덱스 값도 줌,  _, == not의 의미이고 변수로 쓰지 않겠다. 즉 인덱스 번화와 값중 값(pred만 가져온다)\n","    n_correct += (pred == labels).sum().item() # .itemd = 값만 가져옴\n","    n_samples += labels.size(0)\n","\n","  acc = n_correct / n_samples * 100\n","  print(f'ACC: {acc:.3f}')"],"metadata":{"id":"fTrKPtbwqDB3","executionInfo":{"status":"aborted","timestamp":1687419188850,"user_tz":-540,"elapsed":7,"user":{"displayName":"유영준","userId":"02892448869014284071"}}},"execution_count":null,"outputs":[]}]}